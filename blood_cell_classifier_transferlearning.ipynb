{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c955dee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LIBRARIES\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "import matplotlib.pyplot as plt # Visualization\n",
    "import seaborn as sb # Visualization\n",
    "import PIL #Image viewer\n",
    "\n",
    "# import glob to return all file paths that match a specific pattern\n",
    "import os\n",
    "from glob import glob\n",
    "import itertools\n",
    "\n",
    "# for Compatibility\n",
    "from __future__ import print_function, division\n",
    "from builtins import range, input\n",
    "\n",
    "# Include tensorflow keras layers, models, and preprocessing\n",
    "\n",
    "from tensorflow import keras \n",
    "from tensorflow.keras.layers import Input, Lambda, Dense, Flatten\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50\n",
    "from tensorflow.keras.applications.resnet50 import preprocess_input\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "#Importing confusion matrix to describe the performance of the model\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce32e2ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Include the directories of the dataset\n",
    "train_path = '../Dataset/blood_cell_images/TRAIN'\n",
    "valid_path = '../Dataset/blood_cell_images/TEST'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd433749",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the files from the directories\n",
    "image_files = glob(train_path + '/*/*.jp*g')\n",
    "valid_image_files = glob(valid_path + '/*/*.jp*g')\n",
    "folders = glob(train_path + '/*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79a35282",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the length of training data\n",
    "print(len(image_files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e62ec37b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the length of validation data\n",
    "print(len(valid_image_files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b55d457",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the number of classes\n",
    "print(len(folders))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dfea32d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# View a sample image\n",
    "plt.imshow(image.img_to_array(image.load_img(np.random.choice(image_files))).astype('uint8'))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3f7a3bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# re-size all the images to this\n",
    "IMAGE_SIZE = [224, 224] # feel free to change depending on dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8db24a13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# training config:\n",
    "epochs = 3 # Increase the epochs or use callbacks\n",
    "batch_size = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cec320ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add preprocessing layer to the front of VGG\n",
    "res = ResNet50(input_shape=IMAGE_SIZE + [3], weights='imagenet', include_top=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeff9995",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if you don't want to train existing weights, set False\n",
    "# set True to Fine tune\n",
    "for layer in res.layers:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b8d4650",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding the last layer corresponding to the number of classes.\n",
    "# Use Softmax for multiclass classifcation\n",
    "# More hidden layers can be added\n",
    "x = Flatten()(res.output)\n",
    "prediction = Dense(len(folders), activation='softmax')(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aedf23b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a model object\n",
    "model = Model(inputs=res.input, outputs=prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5395ca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# view the structure of the model\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49214599",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tell the model what cost and optimization method to use\n",
    "model.compile(\n",
    "  loss='categorical_crossentropy',\n",
    "  optimizer='adam',\n",
    "  metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df65e408",
   "metadata": {},
   "source": [
    "How does ImageDataGenerator works!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2ca8c63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an instance of ImageDataGenerator\n",
    "\n",
    "train_gen = ImageDataGenerator(\n",
    "  rotation_range=20,\n",
    "  width_shift_range=0.1,\n",
    "  height_shift_range=0.1,\n",
    "  shear_range=0.1,\n",
    "  zoom_range=0.2,\n",
    "  horizontal_flip=True,\n",
    "  vertical_flip=True,\n",
    "  preprocessing_function=preprocess_input\n",
    ")\n",
    "\n",
    "val_gen = ImageDataGenerator(preprocessing_function = preprocess_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "646e4b1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_gen = val_gen.flow_from_directory(valid_path, target_size = IMAGE_SIZE)\n",
    "print(test_gen.class_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf5e04bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [None] * len(test_gen.class_indices)\n",
    "for k, v in test_gen.class_indices.items():\n",
    "    labels[v] = k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a8fdf4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bbde06e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# should be a strangely colored image (due to VGG weights being BGR)\n",
    "for x, y in test_gen:\n",
    "    print(\"min:\", x[0].min(), \"max:\", x[0].max())\n",
    "    plt.title(labels[np.argmax(y[0])])\n",
    "    plt.imshow(x[0])\n",
    "    plt.show()\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d6be7ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create generators\n",
    "train_generator = train_gen.flow_from_directory(\n",
    "  train_path,\n",
    "  target_size=IMAGE_SIZE,\n",
    "  shuffle=True,\n",
    "  batch_size=batch_size,\n",
    ")\n",
    "\n",
    "valid_generator = val_gen.flow_from_directory(\n",
    "  valid_path,\n",
    "  target_size=IMAGE_SIZE,\n",
    "  shuffle=True,\n",
    "  batch_size=batch_size,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b46cc87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit the model\n",
    "r = model.fit(\n",
    "  train_generator,\n",
    "  validation_data=valid_generator,\n",
    "  epochs=epochs,\n",
    "  steps_per_epoch=len(image_files) // batch_size,\n",
    "  validation_steps=len(valid_image_files) // batch_size,\n",
    ")\n",
    "\n",
    "# rms prop vs Adam\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d909cfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss\n",
    "plt.plot(r.history['loss'], label='train loss')\n",
    "plt.plot(r.history['val_loss'], label='val loss')\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb670638",
   "metadata": {},
   "outputs": [],
   "source": [
    "# accuracies\n",
    "plt.plot(r.history['accuracy'], label='train acc')\n",
    "plt.plot(r.history['val_accuracy'], label='val acc')\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93aaed9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_confusion_matrix(data_path, N):\n",
    "    print(\"Generating confusion matrix\", N)\n",
    "    predictions = []\n",
    "    targets = []\n",
    "    i = 0\n",
    "    for x, y in val_gen.flow_from_directory(data_path, target_size=IMAGE_SIZE, shuffle=False, batch_size=batch_size * 2):\n",
    "        i += 1\n",
    "        if i % 50 == 0:\n",
    "            print(i)\n",
    "        p = model.predict(x)\n",
    "        p = np.argmax(p, axis=1)\n",
    "        y = np.argmax(y, axis=1)\n",
    "        predictions = np.concatenate((predictions, p))\n",
    "        targets = np.concatenate((targets, y))\n",
    "        if len(targets) >= N:\n",
    "            break\n",
    "\n",
    "    cm = confusion_matrix(targets, predictions)\n",
    "    return cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8596ce68",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = get_confusion_matrix(train_path, len(image_files))\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ada4f3f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_cm = get_confusion_matrix(valid_path, len(valid_image_files))\n",
    "print(valid_cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea703f0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import plot_confusion_matrix\n",
    "plot_confusion_matrix(cm, labels, title='Train confusion matrix')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fabc2775",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix(valid_cm, labels, title='Validation confusion matrix')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a7a68cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "r.history.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27582321",
   "metadata": {},
   "outputs": [],
   "source": [
    "score = r.model.evaluate(valid_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a95c67a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40e31f19",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Model Accuracy: %{score[1]*100}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21467b45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# r.model.save(\"./\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
